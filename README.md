# Description
Code for machine learning with Apache Spark and a final project integrating ETL, pipeline creation, model evaluation, and model management for future use.

The final project code familiarizes users with the essential processes of data processing and machine learning model creation using Apache Spark. The project is divided into four main parts:

# Part 1: Performing ETL Activities (Extract, Transform, Load)
Load a CSV file: Import a CSV dataset into a Spark DataFrame.

Remove duplicates: Identify and eliminate duplicate rows in the data.

Remove null values: Clean the data by removing rows with missing values.

Perform transformations: Apply necessary transformations to prepare the data.

Store cleaned data: Save the cleaned data in Parquet format for future use.

# Part 2: Creating a Machine Learning Pipeline
Create a machine learning pipeline: Set up a complete pipeline for the prediction process, including data transformation steps and application of machine learning algorithms.

# Part 3: Evaluating the Model
Evaluate the model: Use appropriate metrics to assess the model's performance and ensure its reliability and effectiveness.

# Part 4: Persisting the Model
Save the model: Store the trained machine learning model for production use.

Load and verify the stored model: Load the saved model and check its integrity and functionality.
